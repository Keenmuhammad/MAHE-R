{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Keenmuhammad/MAHE-R/blob/main/Webinar6(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Load essential libraries\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0_BbyTKXQflD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler"
      ],
      "metadata": {
        "id": "20W0d4ruQjE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Demonstration of splitting samples into batches for batch processing using a simple example\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4PA3YCYjerWB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtKh7DZWkCMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51fac2d-a27a-493f-f6d2-b15e907bca68"
      },
      "source": [
        "num_samples = 11 # total number of samples\n",
        "num_iters = 10   # number of iterations\n",
        "batch_size = 16   # number of samples for calculating loss and gradient in each iteration\n",
        "\n",
        "print('Number of samples = %d'%(num_samples))\n",
        "print('Number of iterations = %d'%(num_iters))\n",
        "print('Batch size = %d'%(batch_size))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples = 11\n",
            "Number of iterations = 10\n",
            "Batch size = 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "User-defined function to generate sample indices for batch processing according to batch size\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BzkJAqOaevwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(3, 10, 2)\n",
        "np.random.choice([10, 20, 30, 40, 50], 3, replace = True, p = [0.1, 0.1, 0.2, 0.2, 0.4])\n",
        "myarray = np.arange(10)\n",
        "print(myarray)\n",
        "chunks = np.array_split(myarray, 6)\n",
        "chunks = np.array_split(myarray, [3, 6, 9])\n",
        "print(chunks)\n",
        "print(type(chunks))\n",
        "#print(chunks.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWzX7yv3xHaR",
        "outputId": "72480ec9-b9a5-481e-c287-3957791c1031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "[array([0, 1, 2]), array([3, 4, 5]), array([6, 7, 8]), array([9])]\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reordered_sample_indices = np.random.choice(num_samples, num_samples, replace = False)\n",
        "print(reordered_sample_indices)\n",
        "print(np.arange(batch_size, num_samples, batch_size))\n",
        "np.array_split(reordered_sample_indices, np.arange(batch_size, len(reordered_sample_indices), batch_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3US2LpA1FNx",
        "outputId": "16209013-14d2-49eb-d9f3-9c57a3015e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 6  3  5  1  4 10  2  9  0  7  8]\n",
            "[3 6 9]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([6, 3, 5]), array([ 1,  4, 10]), array([2, 9, 0]), array([7, 8])]"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_indices():\n",
        "  # Reorder sample indices\n",
        "  reordered_sample_indices = np.random.choice(num_samples, num_samples, replace = False)\n",
        "  # Generate batch indices for batch processing\n",
        "  batch_indices = np.array_split(reordered_sample_indices, np.arange(batch_size, len(reordered_sample_indices), batch_size))\n",
        "  return(batch_indices)"
      ],
      "metadata": {
        "id": "ks4Yx0HNQ4sU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_batch_indices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbHP0rtn6nx_",
        "outputId": "81c107fd-4536-4831-be58-9ab593937c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 7, 0]), array([6, 2, 9]), array([8, 4, 3]), array([10,  5])]"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "The batch processiong loop\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "dqLN2H2HVl9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(1000)\n",
        "range(1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yPrnbgB_xFH",
        "outputId": "69f8d534-987b-4f8b-83ec-e7f16135bc56"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for it in range(11):\n",
        "  print(it)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K07i6La_6Sh",
        "outputId": "b3f385d5-b182-4656-c2c1-5da70ce41f20"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of batches per epoch\n",
        "num_iterations_per_epoch = int(np.ceil(num_samples/batch_size)) \n",
        "print('Number of iterations per epoch = %d\\n'%(num_iterations_per_epoch))\n",
        "b = 0\n",
        "epoch = 0\n",
        "for it in range(num_iters):\n",
        "  if it % num_iterations_per_epoch == 0:# check if we are at the start of an epoch\n",
        "    print('--------------------------------')\n",
        "    print('Epoch %d:'%(epoch))\n",
        "    batch_indices = generate_batch_indices()\n",
        "    b = 0 \n",
        "    epoch = epoch + 1   \n",
        "    print('--------------------------------')\n",
        "  print('In iteration %d, using samples' % (it))\n",
        "  print(batch_indices[b])  \n",
        "  b += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTAv0Ci2VcA4",
        "outputId": "c0a02680-1701-4cac-8365-9828f8c147d8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of iterations per epoch = 1\n",
            "\n",
            "--------------------------------\n",
            "Epoch 0:\n",
            "--------------------------------\n",
            "In iteration 0, using samples\n",
            "[ 5  8  2  6  0  9  4 10  7  3  1]\n",
            "--------------------------------\n",
            "Epoch 1:\n",
            "--------------------------------\n",
            "In iteration 1, using samples\n",
            "[ 9  7  0  4 10  3  2  6  1  8  5]\n",
            "--------------------------------\n",
            "Epoch 2:\n",
            "--------------------------------\n",
            "In iteration 2, using samples\n",
            "[10  0  9  8  5  4  2  1  3  7  6]\n",
            "--------------------------------\n",
            "Epoch 3:\n",
            "--------------------------------\n",
            "In iteration 3, using samples\n",
            "[ 8  0  3  1  9  5  7  2  4  6 10]\n",
            "--------------------------------\n",
            "Epoch 4:\n",
            "--------------------------------\n",
            "In iteration 4, using samples\n",
            "[ 7  8  4  0 10  2  9  6  1  5  3]\n",
            "--------------------------------\n",
            "Epoch 5:\n",
            "--------------------------------\n",
            "In iteration 5, using samples\n",
            "[ 2  7  1  6  5  3 10  4  0  9  8]\n",
            "--------------------------------\n",
            "Epoch 6:\n",
            "--------------------------------\n",
            "In iteration 6, using samples\n",
            "[ 9  3  6  4  7  2 10  8  1  5  0]\n",
            "--------------------------------\n",
            "Epoch 7:\n",
            "--------------------------------\n",
            "In iteration 7, using samples\n",
            "[10  0  7  6  8  4  9  1  3  5  2]\n",
            "--------------------------------\n",
            "Epoch 8:\n",
            "--------------------------------\n",
            "In iteration 8, using samples\n",
            "[ 2 10  4  0  1  6  5  8  9  3  7]\n",
            "--------------------------------\n",
            "Epoch 9:\n",
            "--------------------------------\n",
            "In iteration 9, using samples\n",
            "[ 1 10  7  6  8  4  0  5  2  3  9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Generate artificial data with 11 samples, 2 features per sample and 3 output classes.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jAYpx802XT1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 11 # number of samples\n",
        "num_features = 2 # number of features (a.k.a. dimensionality)\n",
        "num_labels = 3 # number of output labels\n",
        "\n",
        "# Data matrix (each column = single sample)\n",
        "X = np.random.choice(np.arange(0, 5), size = (num_features, num_samples), replace = True)\n",
        "\n",
        "# Class labels\n",
        "y = np.random.choice([0, 1, 2], size = num_samples, replace = True)\n",
        "\n",
        "print('Data matrix X = ')\n",
        "print(X)\n",
        "print('Data labels y = ')\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf2SGwDvXUM4",
        "outputId": "aa30c1f4-d410-4e00-b85d-184c181ec152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data matrix X = \n",
            "[[4 2 0 0 2 2 1 0 2 1 4]\n",
            " [2 0 3 3 3 0 1 4 2 3 3]]\n",
            "Data labels y = \n",
            "[0 2 2 0 1 0 0 0 1 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Batch gradient descent for the softmax classification algorithm\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "KTd1dynKYJgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial weights matrix\n",
        "W = 0.01 * np.random.randn(num_labels, num_features)\n",
        "\n",
        "num_iters = 10        # number of iterations\n",
        "batch_size = 3        # number of samples in each batch\n",
        "learning_rate = 1e-02 # learning rate\n",
        "\n",
        "print('Number of samples = %d'%(num_samples))\n",
        "print('Number of iterations = %d'%(num_iters))\n",
        "print('Batch size = %d'%(batch_size))\n",
        "\n",
        "## Batch Gradient descent loop\n",
        "b = 0\n",
        "epoch = 0\n",
        "num_batches_per_epoch = int(np.ceil(num_samples/batch_size)) # number of batches per epoch\n",
        "print('Number of batches per epoch = %d\\n'%(num_batches_per_epoch))\n",
        "it_loss_history = [] # initialize empty list for storing loss history over each iteration\n",
        "epoch_loss_history = [] # initialize empty list for storing loss history over each epoch\n",
        "\n",
        "for it in range(num_iters):\n",
        "  # Generate batch indices if all samples have been seen at this iteration\n",
        "  if it % num_batches_per_epoch == 0:\n",
        "    batch_indices = generate_batch_indices()\n",
        "    b = 0\n",
        "    if epoch >= 1:\n",
        "      epoch_avg_loss = np.mean(it_loss_history[it-len(batch_indices):it])\n",
        "      print('----------------------------------')\n",
        "      print('Epoch: %d, Loss = %f' % (epoch, epoch_avg_loss))  \n",
        "      print('----------------------------------')\n",
        "      epoch_loss_history.append(epoch_avg_loss) # append average epoch loss  \n",
        "    epoch = epoch + 1 \n",
        "      \n",
        "  # Evaluate loss and gradient on batch samples\n",
        "  batch_sample_size = len(batch_indices[b]) # number of samples in each batch\n",
        "  \n",
        "  # Calculate the scores matrix\n",
        "  S = np.dot(W, X[:, batch_indices[b]])\n",
        "\n",
        "  # Calculate the probability matrix\n",
        "  P = np.exp(S) / np.sum(np.exp(S), axis = 0)\n",
        "\n",
        "  # Calculate loss for all samples in current batch\n",
        "  loss = -np.log(P[y[batch_indices[b]], np.arange(batch_sample_size)])\n",
        "\n",
        "  # Calculate total average data loss for current batch\n",
        "  loss_data = np.mean(loss)\n",
        "    \n",
        "  # Adjust probability matrix such that 1 is subtracted from each batch sample's\n",
        "  # correct category probability\n",
        "  P[y[batch_indices[b]], np.arange(batch_sample_size)] -= 1\n",
        "\n",
        "  # Calculate the gradient w.r.t. weights of the data loss\n",
        "  dW = (1/batch_sample_size) * np.dot(P, X[:, batch_indices[b]].T) \n",
        "\n",
        "  # Update weights matrix\n",
        "  W = W - learning_rate * dW\n",
        "   \n",
        "  # Append iteration loss history and print loss once every iteration\n",
        "  it_loss_history.append(loss_data)\n",
        "  print('# In iteration %d, using samples' % (it+1))\n",
        "  print(batch_indices[b]) \n",
        "  print('Loss = %f'%(loss_data))\n",
        "  \n",
        "  b += 1 "
      ],
      "metadata": {
        "id": "8se9Ym9FYGN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Ws the jury selection biased?**\n",
        "\n",
        "---\n",
        "\n",
        "In 1963, a county court in Alabama, U.S.A, convicted a young African-American man named Robert Swain of a heinous crime and sentenced him to death. At the time, only men aged 21 or older were allowed to serve on juries in that county where in 26% of the eligible jurors were African-American. However, for the 100-member jury panel for the case's trial, only 8 eligible African-American men were selected. None of those selected 8 African-American men ended up being part of the actual jury panel for the trial. Mr. Swain appealed his sentence, citing among other factors the all-Caucasian jury.\n",
        "\n",
        "In 1965, the Supreme Court of the United States denied Swain’s appeal. In its ruling, the Court observed that the overall percentage disparity of African-Americans has been small and was not due to any concerted effort.\n",
        "\n",
        "The percentage disparity in this case was 8% (the percentage of African-American jurors on the jury panel) compared to 26% (the percentage of African-American people eligible for jury service). How could we decide if that quoted disparity is small?\n",
        "\n",
        "---\n",
        "\n",
        "To answer this question, we will simulate a jury pool assuming that that each juror has been randomly selected from the eligible population. That is, for any one juror, there is a probability of 26% that they are African-American.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "dmcsWxTIac7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate a 100-member jury panel\n",
        "Jury_Panel = np.random.choice(['C', 'A'], size = 100, replace = True, p = [0.74, 0.26])\n",
        "a = np.mean(Jury_Panel == 'A')\n",
        "b = np.count_nonzero(Jury_Panel == 'A')\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "OV0BLY4Wc4K5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af9bee46-4030-4de6-e066-95fe5b740006"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.39\n",
            "39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "We will now simualte the 100-member jury panel several times and see if it is actually reasonably likely to have a jury panel with 8 African-Americans.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "K9HMXW55fZj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nsimulations = 100\n",
        "# Make an empty counts array, to append to\n",
        "counts = np.array([], dtype = int)\n",
        "for j in range(nsimulations):\n",
        "  Jury_Panel = np.random.choice(['C', 'A'], size = 100, replace = True, p = [0.74, 0.26])\n",
        "  counts = np.append(counts, np.count_nonzero(Jury_Panel == 'A'))   "
      ],
      "metadata": {
        "id": "3cbuAJmOflkJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Plot a histogram of the number of African-American jurors.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "5o9xtwa1h06x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize = (10, 6))\n",
        "fig.tight_layout(pad = 4.0)\n",
        "binwidth = 2\n",
        "ax.hist(counts, bins = range(min(counts), max(counts) + binwidth, binwidth))\n",
        "ax.set_xlabel('No. of African American Jurors', fontsize = 14)\n",
        "ax.set_ylabel('Count', fontsize = 14)\n",
        "ax.set_xticks(range(min(counts), max(counts) + binwidth, binwidth));"
      ],
      "metadata": {
        "id": "wdiIMdXEh5tC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "cecd4950-c691-460a-82e3-14528557ce6c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Load the iris dataset\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "FPpQ-TBukETG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "Zgr6EZXDkOEq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "What is inside the 'iris' object?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "fLoqQdChkPZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(iris)\n",
        "X = iris.data\n",
        "print(type(X))\n",
        "print(X.shape)"
      ],
      "metadata": {
        "id": "9EXq4XvxkYH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2481093b-4e18-42cb-9cb3-bf87ec9091da"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(150, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = X[:, 2]\n",
        "#print(np.sum(a)/len(a))\n",
        "print(np.mean(a))\n",
        "print(np.median(a))\n",
        "# What fraction of samples have a sepal length <= median sepal length\n",
        "#print(a)\n",
        "#print(np.mean(a >= np.median(a))*100) \n",
        "# Median is the 50th percentile\n",
        "#print(np.percentile(a, 50))\n",
        "# 90th percentile\n",
        "#print(np.percentile(a, 90))\n",
        "#print(np.mean(a <= np.percentile(a, 90))*100)\n",
        "print(np.var(a))\n",
        "np.mean((a - np.mean(a))**2)\n",
        "print(np.std(a))\n",
        "np.sqrt(np.mean((a - np.mean(a))**2))"
      ],
      "metadata": {
        "id": "_2JKQTXpkkO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Plot a histogram of the number of sepal lengths.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "KRZpglROktcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize = (10, 6))\n",
        "fig.tight_layout(pad = 4.0)\n",
        "binwidth = 2\n",
        "ax.hist(counts, bins = range(min(counts), max(counts) + binwidth, binwidth))\n",
        "ax.set_xlabel('Sepal length', fontsize = 14)\n",
        "ax.set_ylabel('Count', fontsize = 14)\n",
        "ax.set_title('Sepal Length Distribution in Iris Flower', fontsize = 16)\n",
        "ax.set_xticks(range(min(counts), max(counts) + binwidth, binwidth));"
      ],
      "metadata": {
        "id": "gkVFIFTqkxIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "User-defined function to make a component plot of an array\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "stJmyZ-flRI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotveccomp(x, name = None, axis = None):\n",
        "  ax = axis\n",
        "  component_index = range(0, len(x))\n",
        "  ax.plot(component_index, x, color = 'black', marker = 'o') \n",
        "  ax.plot(component_index, [np.mean(x)]*len(x), linewidth = 1, linestyle = 'dashed', color ='blue') \n",
        "  ax.plot(component_index, [np.mean(x) - np.std(x)]*len(x), linewidth = 1, linestyle = 'dashed', color ='red')\n",
        "  ax.plot(component_index, [np.mean(x) + np.std(x)]*len(x), linewidth = 1, linestyle = 'dashed', color ='red')\n",
        "  ax.set_xlabel('Sample #', fontsize = 16)\n",
        "  ax.set_ylabel(name, fontsize = 16)\n",
        "  ax.set_title(' '.join(name.split()[0:2]) +  ' Array', fontsize = 14)"
      ],
      "metadata": {
        "id": "TbELW5h5lQvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax1 = plt.subplots(1, 1, figsize = (8, 8))\n",
        "fig.tight_layout(pad = 4.0)\n",
        "plotveccomp(a, 'Sepal Length', ax1)"
      ],
      "metadata": {
        "id": "y8z_dWpclguW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Mount Google Drive folder\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "imohJRqynJBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IbzObNaGnMPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Setup working directory and data directory.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "1xth6Akbmhjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/Office of Online Education/'\n",
        "DATA_DIR = DIR + 'Data/'"
      ],
      "metadata": {
        "id": "hDTbe7NKmh9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Load Data\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "5hmtna_0msSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FILE = DATA_DIR + 'food-texture.csv'\n",
        "df_food = pd.read_csv(FILE, index_col = 0)\n",
        "df_food.head()"
      ],
      "metadata": {
        "id": "1np3DDRBmw83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Print the names of the rows & columns in the dataframe\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "A5fLF76gnUVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_food.index)\n",
        "print(df_food.columns)"
      ],
      "metadata": {
        "id": "TKVJoRianafW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Get values in the 'Density' column\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "KvqycbPPnceM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_food['Density'])"
      ],
      "metadata": {
        "id": "V8GbAbG-nhA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Get features for the sample B136\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "67hIG7zknjBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_food.loc['B136', :])"
      ],
      "metadata": {
        "id": "ys-gzaWgnnSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Get 'Oil' and 'Density' values for the samples B136 and B225.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "p6RCvOgLnoKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = ['Oil', 'Density']\n",
        "sample_names = ['B136', 'B225']\n",
        "#df_food[feature_names]\n",
        "df_food_sub = df_food.loc[sample_names, feature_names]\n",
        "print(df_food_sub)"
      ],
      "metadata": {
        "id": "J8WyHpCMnvZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Object type\n",
        "#type(df_food)\n",
        "#type(df_food['Oil'])\n",
        "#type(df_food['Oil'].values)\n",
        "#type(df_food.loc['B136', :])\n",
        "#type(df_food.loc['B136', 'Oil'])\n",
        "#df_food['Oil'].dtype\n",
        "#type(df_food[feature_names])\n",
        "#df_food[feature_names].dtypes\n",
        "df_food.dtypes"
      ],
      "metadata": {
        "id": "MtvqoLkEny7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Create a list of continuous and categorical column names and set types accordingly\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "-r6lgRwjnzsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "continuous_cols = ['Oil', 'Density', 'Fracture', 'Hardness']\n",
        "categorical_cols = ['Crispy']\n",
        "\n",
        "# Typecasting\n",
        "df_food[categorical_cols] = df_food[categorical_cols].astype('category')\n",
        "df_food[continuous_cols] = df_food[continuous_cols].astype('float64')\n",
        "\n",
        "df_food.dtypes"
      ],
      "metadata": {
        "id": "8CWeYghun8cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Simulating a data centre-resource dataframe\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0TSii1KXo62X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(100)\n",
        "nsamples = 10\n",
        "colnames = ['Number of Cores', 'Memory', 'Disk Space', 'Network Bandwidth']\n",
        "data = zip(np.random.choice(np.arange(2,17), nsamples),\n",
        "           np.random.choice([16, 32, 64, 128], nsamples),\n",
        "           np.random.choice([128, 256, 512, 1024], nsamples),\n",
        "           np.random.choice(100*np.arange(2, 11), nsamples))\n",
        "df_resource = pd.DataFrame(list(data), columns = colnames)\n",
        "df_resource['Power Consumption'] = np.random.normal(2, df_resource['Memory'] / (np.max(df_resource['Memory'])-np.min(df_resource['Memory'])), nsamples)\n",
        "df_resource.head()"
      ],
      "metadata": {
        "id": "_pxf40MXo9Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Handling time series data\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "pGSL7Bnyq-u1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FILE = DATA_DIR + 'testdata.csv'\n",
        "df = pd.read_csv(FILE, sep = \",\", header = 0)\n",
        "df['time'] = pd.to_datetime(df['time'], format='%m-%d-%Y %H.%M')\n",
        "df.loc[:, (df.columns != 'time')] = df.loc[:, df.columns != 'time'].apply(pd.to_numeric, errors = 'coerce')\n",
        "df = df.set_index('time')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "f4gFLUVOrBW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Plot percentage of missing values (NaNs) for each feature\n",
        "cutoff = 30\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "percent_missing = (df.isna().sum() / df.shape[0]) * 100\n",
        "percent_missing.plot(kind = 'bar', color = cm.rainbow(np.linspace(0, 1, 2))[(percent_missing <= cutoff).values.astype(int)])\n",
        "plt.plot(np.arange(df.shape[1]), np.repeat(cutoff, df.shape[1]), 'g--') \n",
        "fig.suptitle('Percentage Missing Values Across All Features', fontsize = 20)\n",
        "plt.xlabel('Feature', fontsize = 16)\n",
        "plt.ylabel('% Missing Values', fontsize = 16)"
      ],
      "metadata": {
        "id": "gUfqNpserYTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Linear interpolation for one column\n",
        "#df['Cyclone_Inlet_Gas_Temp'] = df['Cyclone_Inlet_Gas_Temp'].interpolate(method = 'linear')\n",
        "df.loc[:, (df.columns != 'time')] = df.loc[:, df.columns != 'time'].interpolate(method = 'linear')\n",
        "(df.isna().sum() / df.shape[0]) * 100"
      ],
      "metadata": {
        "id": "d0aBAaHgrmPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer"
      ],
      "metadata": {
        "id": "F8r4lAOOr_Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature = df.columns[0] # \n",
        "sampling_period = 1 # in seconds of the dataset as provided\n",
        "time_period = '10min' # for each sample\n",
        "scaler = {'identity': FunctionTransformer(lambda x: x), 'standard': StandardScaler()}\n",
        "df1 = pd.DataFrame(scaler['identity'].fit_transform(df))\n",
        "df1.index = df.index.copy()\n",
        "df1.columns = df.columns.copy()\n",
        "df_samples = df1.groupby(pd.Grouper(freq = time_period)).apply(lambda x: x[feature].values if len(x[feature].values) == int(pd.Timedelta(time_period).total_seconds()) else np.nan)\n",
        "df_samples = df_samples.dropna()\n",
        "df_samples.head()"
      ],
      "metadata": {
        "id": "1zzjy4wwrnGr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}